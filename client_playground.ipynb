{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce54b714cb6b4534b46c5b8b8c24d999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/epuerta/.local/share/hatch/env/pip-compile/kitchenai/H8pmQr2m/dev/lib/python3.11/site-packages/dj_notebook/__\n",
       "init__.py:76: UserWarning: Django is running in production mode with dj-notebook.\n",
       "  warnings.warn(\"Django is running in production mode with dj-notebook.\")\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/epuerta/.local/share/hatch/env/pip-compile/kitchenai/H8pmQr2m/dev/lib/python3.11/site-packages/dj_notebook/__\n",
       "init__.py:76: UserWarning: Django is running in production mode with dj-notebook.\n",
       "  warnings.warn(\"Django is running in production mode with dj-notebook.\")\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dj_notebook import activate\n",
    "import os \n",
    "os.environ[\"AWS_S3_VERIFY\"] = \"false\"\n",
    "plus = activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /home/epuerta/.local/share/hatch/env/pip-compile/kitchenai/H8pmQr2m/dev/lib/python3.11/site-packages (1.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'whisk.kitchenai_sdk.http_schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwhisk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkitchenai_sdk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhttp_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatExtraBody\n\u001b[1;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8001/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m chat_extra_body \u001b[38;5;241m=\u001b[39m ChatExtraBody(\n\u001b[1;32m      7\u001b[0m     client_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )   \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'whisk.kitchenai_sdk.http_schema'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from whisk.kitchenai_sdk.http_schema import ChatExtraBody\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:8001/v1\")\n",
    "\n",
    "chat_extra_body = ChatExtraBody(\n",
    "    client_id=\"llama-index\",\n",
    "    namespace=\"llama-index\",\n",
    "    label=\"query\",\n",
    "    version=\"1.0.0\",\n",
    ")   \n",
    "\n",
    "print(chat_extra_body.model_dump())\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"whats the most important part of the readme?\"}],\n",
    "    metadata={\"user_id\": \"123\"},\n",
    "    extra_body=chat_extra_body.model_dump()\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INFO HTTP Request: POST http://localhost:8001/v1/files \"HTTP/1.1 200 OK\"\n",
       "</pre>\n"
      ],
      "text/plain": [
       "INFO HTTP Request: POST http://localhost:8001/v1/files \"HTTP/1.1 200 OK\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='36', bytes=6275, created_at=1738281132, filename='README.md', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {\"user_id\": \"123\", \"other_key\": \"value\"}}', status='pending', status_details=None)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from whisk.kitchenai_sdk.http_schema import FileExtraBody   \n",
    "\n",
    "file_extra_body = FileExtraBody(\n",
    "    client_id=\"llama-index\",\n",
    "    namespace=\"llama-index\",\n",
    "    label=\"storage\",\n",
    "    version=\"1.0.0\",\n",
    "    metadata=\"user_id=123,other_key=value\"  # Changed to string format\n",
    ")\n",
    "\n",
    "response = client.files.create(\n",
    "    file=open(\"README.md\", \"rb\"),\n",
    "    purpose=\"chat\",\n",
    "    extra_body=file_extra_body.model_dump()\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INFO HTTP Request: GET http://localhost:8001/v1/files \"HTTP/1.1 200 OK\"\n",
       "</pre>\n"
      ],
      "text/plain": [
       "INFO HTTP Request: GET http://localhost:8001/v1/files \"HTTP/1.1 200 OK\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FileObject](data=[FileObject(id='29', bytes=6275, created_at=1738270803, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='failed', status_details=None), FileObject(id='28', bytes=6275, created_at=1738270802, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='failed', status_details=None), FileObject(id='27', bytes=6275, created_at=1738270801, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='failed', status_details=None), FileObject(id='26', bytes=6275, created_at=1738270742, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='25', bytes=6275, created_at=1738270741, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='24', bytes=6275, created_at=1738270740, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='23', bytes=6275, created_at=1738269943, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='22', bytes=6275, created_at=1738269534, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='21', bytes=6275, created_at=1738260718, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='20', bytes=6275, created_at=1738260437, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='19', bytes=6275, created_at=1738260384, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='18', bytes=6275, created_at=1738260239, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='17', bytes=6275, created_at=1738260061, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='16', bytes=6275, created_at=1738260023, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='13', bytes=6275, created_at=1738228910, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='12', bytes=6275, created_at=1738228751, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='11', bytes=6275, created_at=1738228434, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='10', bytes=6275, created_at=1738228275, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='9', bytes=6275, created_at=1738228064, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='8', bytes=6275, created_at=1738227978, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='7', bytes=6275, created_at=1738227920, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='6', bytes=6275, created_at=1738227796, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='5', bytes=6275, created_at=1738226899, filename='README.md', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='4', bytes=355606, created_at=1738226303, filename='onboarding-dev.png', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='3', bytes=355606, created_at=1738226019, filename='onboarding-dev.png', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='2', bytes=355606, created_at=1738225845, filename='onboarding-dev.png', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='1', bytes=355606, created_at=1738225714, filename='onboarding-dev.png', object='file', purpose='{\"client_id\": \"openai-simple\", \"namespace\": \"openai-simple\", \"label\": \"chat\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='36', bytes=6275, created_at=1738281132, filename='README.md', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {\"user_id\": \"123\", \"other_key\": \"value\"}}', status='completed', status_details=None), FileObject(id='35', bytes=176299, created_at=1738281091, filename='consultancy-rfp.pdf', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {\"ee\": \"ee\"}}', status='completed', status_details=None), FileObject(id='34', bytes=176299, created_at=1738281035, filename='consultancy-rfp.pdf', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {\"ee\": \"eee\"}}', status='pending', status_details=None), FileObject(id='31', bytes=6275, created_at=1738278358, filename='README.md', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {}}', status='pending', status_details=None), FileObject(id='30', bytes=6275, created_at=1738275821, filename='README.md', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {}}', status='completed', status_details=None)], object='list')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">INFO HTTP Request: GET http://localhost:8001/v1/files/36 \"HTTP/1.1 200 OK\"\n",
       "</pre>\n"
      ],
      "text/plain": [
       "INFO HTTP Request: GET http://localhost:8001/v1/files/36 \"HTTP/1.1 200 OK\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "FileObject(id='36', bytes=6275, created_at=1738281132, filename='README.md', object='file', purpose='{\"client_id\": \"llama-index\", \"namespace\": \"llama-index\", \"label\": \"storage\", \"version\": \"0.0.1\", \"metadata\": {\"user_id\": \"123\", \"other_key\": \"value\"}}', status='completed', status_details=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.retrieve(\"36\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.files.delete(\"15\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
